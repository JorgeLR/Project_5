{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client Project - Problem 2: Leveraging News and Media for Situational Awareness\n",
    "## Part 1 - Data Gathering\n",
    "## Problem Statement\n",
    "When disaster strikes, it is critically important to provide the most relevant information to first responders and the general public. During a disaster, people are inundated with a barrage of news sources, resulting in an environment of confusing and misinformation. As of right now, there is no central medium to find relevant news sources for a disaster specific article. The goal of this project is to deliver to the public a website where users can find relevant information and get the key facts during a disaster.\n",
    "\n",
    "## Executive Summary\n",
    "1. Data Gathering\n",
    "2. Data Cleaning and Preprocessing\n",
    "3. Combined Data Tokenized Analysis and Individual Page Content Creation.\n",
    "4. Word2Vec Search Engine, Recommender and Home Page Content Creation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webscraping News API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://newsapi.org/v2/everything?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input API Key from News API before running next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"Put your API key here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wildfire news 10/29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_10_29 = {\n",
    "    'q': 'Wildfire',\n",
    "    'pageSize': 100,\n",
    "    'apiKey': api_key,\n",
    "    'language': 'en',\n",
    "    'from' : '2019-10-29'\n",
    "    \n",
    "}\n",
    "response_10_29 = requests.get(url, params = parameters_10_29)\n",
    "response_json_10_29 = response_10_29.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response_json_10_29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wildfire news 10/26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_10_26 = {\n",
    "    'q': 'Wildfire',\n",
    "    'pageSize': 100,\n",
    "    'apiKey': api_key,\n",
    "    'language': 'en',\n",
    "    'from' : '2019-10-26',\n",
    "    \n",
    "    \n",
    "}\n",
    "response_10_26 = requests.get(url, params = parameters_10_26)\n",
    "response_json_10_26 = response_10_26.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response_json_10_26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wildfire news 10/23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_10_23 = {\n",
    "    'q': 'Wildfire',\n",
    "    'pageSize': 100,\n",
    "    'apiKey': api_key,\n",
    "    'language': 'en',\n",
    "    'from' : '2019-10-23',\n",
    "    \n",
    "    \n",
    "}\n",
    "response_10_23 = requests.get(url, params = parameters_10_23)\n",
    "response_json_10_23 = response_10_23.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response_json_10_23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wildfire news 10/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_10_20 = {\n",
    "    'q': 'Wildfire',\n",
    "    'pageSize': 100,\n",
    "    'apiKey': api_key,\n",
    "    'language': 'en',\n",
    "    'from' : '2019-10-20',\n",
    "   \n",
    "    \n",
    "}\n",
    "response_10_20 = requests.get(url, params = parameters_10_20)\n",
    "response_json_10_20 = response_10_20.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response_json_10_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wildfire news 10/17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_10_17 = {\n",
    "    'q': 'Wildfire',\n",
    "    'pageSize': 100,\n",
    "    'apiKey': api_key,\n",
    "    'language': 'en',\n",
    "    'from' : '2019-10-20',\n",
    "   \n",
    "    \n",
    "}\n",
    "response_10_17 = requests.get(url, params = parameters_10_17)\n",
    "response_json_10_17 = response_10_17.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json_10_17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to Kincade Wildfire happening simultaneously to this project, most news we were able to scrape are related to wildfires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_parameters = {\n",
    "    'q': 'flood',\n",
    "    'pageSize': 100,\n",
    "    'apiKey': api_key,\n",
    "    'language': 'en'\n",
    "}\n",
    "flood_response = requests.get(url, params = flood_parameters)\n",
    "flood_response_json = flood_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tornado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torn_parameters = {\n",
    "    'q': 'tornado',\n",
    "    'pageSize': 100,\n",
    "    'apiKey': api_key,\n",
    "    'language': 'en'\n",
    "}\n",
    "torn_response = requests.get(url, params = torn_parameters)\n",
    "torn_response_json = torn_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Earthquake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earth_parameters = {\n",
    "    'q': 'earthquake',\n",
    "    'pageSize': 100,\n",
    "    'apiKey': api_key,\n",
    "    'language': 'en'\n",
    "}\n",
    "earth_response = requests.get(url, params = earth_parameters)\n",
    "earth_response_json = earth_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hurricane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hurr_parameters = {\n",
    "    'q': 'hurricane',\n",
    "    'pageSize': 100,\n",
    "    'apiKey': api_key,\n",
    "    'language': 'en'\n",
    "}\n",
    "hurr_response = requests.get(url, params = hurr_parameters)\n",
    "hurr_response_json = hurr_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blizzard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blizz_parameters = {\n",
    "    'q': 'blizzard',\n",
    "    'pageSize': 100,\n",
    "    'apiKey': api_key,\n",
    "    'language': 'en'\n",
    "}\n",
    "blizz_response = requests.get(url, params = blizz_parameters)\n",
    "blizz_response_json = blizz_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webscraping cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seeing the keys we need to access the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['status', 'totalResults', 'articles'])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_json.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the JSON file to an organized readable format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_articles_10_29 = response_json_10_29['articles']\n",
    "wildfire_articles_10_26 = response_json_10_26['articles']\n",
    "wildfire_articles_10_23 = response_json_10_23['articles']\n",
    "wildfire_articles_10_20 = response_json_10_20['articles']\n",
    "wildfire_articles_10_17 = response_json_10_17['articles']\n",
    "flood_articles = flood_response_json[\"articles\"]\n",
    "torn_articles = torn_response_json[\"articles\"]\n",
    "earth_articles = earth_response_json[\"articles\"]\n",
    "hurr_articles = hurr_response_json[\"articles\"]\n",
    "blizz_articles = blizz_response_json[\"articles\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function extracts the relevant information from the list of lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(file): \n",
    "    article_results = []\n",
    "    \n",
    "    for i in range(len(file)):\n",
    "        article_dict = {}\n",
    "        article_dict['title'] = file[i]['title']\n",
    "        article_dict['author'] = file[i]['author']\n",
    "        article_dict['source'] = file[i]['source']\n",
    "        article_dict['description'] = file[i]['description']\n",
    "        article_dict['content'] = file[i]['content']\n",
    "        article_dict['pub_date'] = file[i]['publishedAt']\n",
    "        article_dict['url'] = file[i][\"url\"]\n",
    "        article_dict['photo_url'] = file[i]['urlToImage']\n",
    "        \n",
    "        \n",
    "        article_results.append(article_dict)\n",
    "    return article_results\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the wildfire scrape into customized dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_df_10_29 = pd.DataFrame(get_articles(wildfire_articles_10_29))\n",
    "wildfire_df_10_26 = pd.DataFrame(get_articles(wildfire_articles_10_26))\n",
    "wildfire_df_10_23 = pd.DataFrame(get_articles(wildfire_articles_10_23))\n",
    "wildfire_df_10_20 = pd.DataFrame(get_articles(wildfire_articles_10_20))\n",
    "wildfire_df_10_17 = pd.DataFrame(get_articles(wildfire_articles_10_17))\n",
    "flood_df = pd.DataFrame(get_articles(flood_articles))\n",
    "torn_df = pd.DataFrame(get_articles(torn_articles))\n",
    "earth_df = pd.DataFrame(get_articles(earth_articles))\n",
    "hurr_df = pd.DataFrame(get_articles(hurr_articles))\n",
    "blizz_df = pd.DataFrame(get_articles(blizz_articles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the shape of all the dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 8)\n",
      "(100, 8)\n",
      "(100, 8)\n",
      "(100, 8)\n",
      "(100, 8)\n"
     ]
    }
   ],
   "source": [
    "print(wildfire_df_10_29.shape)\n",
    "print(wildfire_df_10_26.shape)\n",
    "print(wildfire_df_10_23.shape)\n",
    "print(wildfire_df_10_20.shape)\n",
    "print(wildfire_df_10_17.shape)\n",
    "print(flood_df.shape)\n",
    "print(torn_df.shape)\n",
    "print(earth_df.shape)\n",
    "print(hurr_df.shape)\n",
    "print(blizz_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function extracts the media source from the dictionared column \"source\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_getter(df):\n",
    "    \n",
    "    source = []\n",
    "    for source_dict in df['source']:\n",
    "        source.append(source_dict['name'])\n",
    "   \n",
    "    df['source'] = source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_getter(wildfire_df_10_29)\n",
    "source_getter(wildfire_df_10_26)\n",
    "source_getter(wildfire_df_10_23)\n",
    "source_getter(wildfire_df_10_20)\n",
    "source_getter(wildfire_df_10_17)\n",
    "source_getter(flood_df)\n",
    "source_getter(torn_df)\n",
    "source_getter(earth_df)\n",
    "source_getter(hurr_df)\n",
    "source_getter(blizz_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This lambda function changed the publication date into something more readable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_df_10_29['pub_date'] = pd.to_datetime(wildfire_df_10_29['pub_date']).apply(lambda x: x.date())\n",
    "wildfire_df_10_26['pub_date'] = pd.to_datetime(wildfire_df_10_26['pub_date']).apply(lambda x: x.date())\n",
    "wildfire_df_10_23['pub_date'] = pd.to_datetime(wildfire_df_10_23['pub_date']).apply(lambda x: x.date())\n",
    "wildfire_df_10_20['pub_date'] = pd.to_datetime(wildfire_df_10_20['pub_date']).apply(lambda x: x.date())\n",
    "wildfire_df_10_17['pub_date'] = pd.to_datetime(wildfire_df_10_17['pub_date']).apply(lambda x: x.date())\n",
    "flood_df['pub_date'] = pd.to_datetime(flood_df['pub_date']).apply(lambda x: x.date())\n",
    "torn_df['pub_date'] = pd.to_datetime(torn_df['pub_date']).apply(lambda x: x.date())\n",
    "earth_df['pub_date'] = pd.to_datetime(earth_df['pub_date']).apply(lambda x: x.date())\n",
    "hurr_df['pub_date'] = pd.to_datetime(hurr_df['pub_date']).apply(lambda x: x.date())\n",
    "blizz_df['pub_date'] = pd.to_datetime(blizz_df['pub_date']).apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining all of the wildfire articles into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_df_pt1 = pd.concat([wildfire_df_10_29,wildfire_df_10_26, \n",
    "                                        wildfire_df_10_23, wildfire_df_10_20,\n",
    "                                        wildfire_df_10_17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_df_pt1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_df_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Dataframe into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfire_df_pt1.to_csv('1.raw_data/teamNJV_wildfire_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_df.to_csv('1.raw_data/teamNJV_flood.csv', index = False)\n",
    "torn_df.to_csv('1.raw_data/teamNJV_tornado.csv', index = False)\n",
    "earth_df.to_csv('1.raw_data/teamNJV_earthquake.csv', index = False)\n",
    "hurr_df.to_csv('1.raw_data/teamNJV_hurricane.csv', index = False)\n",
    "blizz_df.to_csv('1.raw_data/teamNJV_blizzard.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
